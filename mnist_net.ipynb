{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading MNIST data from Pytorch. Splitting in train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train =True, download=True, transform=transforms.Compose([transforms.ToTensor()]))  \n",
    "\n",
    "test = datasets.MNIST(\"\", train =False, download=True, transform=transforms.Compose([transforms.ToTensor()]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring training and testing dataset to batch size value of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size = 10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size = 10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying first batch object from trainset. Output is a list of tensors of size (1, 28, 28) plus a list of labels as int scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([8, 4, 1, 9, 3, 9, 6, 9, 3, 2])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking one datapoint and label from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0745, 0.5961, 1.0000, 0.9961, 0.6431,\n",
      "          0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0118, 0.6392, 0.9961, 0.9961, 0.9961, 0.9961,\n",
      "          0.7922, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1608, 0.9961, 0.8706, 0.1922, 0.1922, 0.9569,\n",
      "          0.9961, 0.4392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.6353, 0.9961, 0.5373, 0.0000, 0.0000, 0.4784,\n",
      "          0.9961, 0.8549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.8039, 0.9961, 0.3216, 0.0000, 0.0000, 0.0078,\n",
      "          0.7294, 0.9922, 0.5020, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.6196, 0.9961, 0.4039, 0.0000, 0.0000, 0.0000,\n",
      "          0.3451, 0.9882, 0.9961, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0824, 0.7451, 0.9961, 0.4039, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.7725, 0.9961, 0.3490, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1922, 0.8706, 0.9961, 0.9961, 0.4039, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.6667, 0.9961, 0.6471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.4588, 0.9961, 0.9059, 0.9961, 0.6667, 0.0941, 0.0000, 0.0000,\n",
      "          0.0000, 0.6667, 0.9961, 0.9059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.8980, 0.9961, 0.3412, 0.4941, 0.5608, 0.4000, 0.0000, 0.0000,\n",
      "          0.0000, 0.6667, 0.9961, 0.9373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667,\n",
      "          0.8314, 0.9961, 0.1647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.6667, 0.9961, 0.9373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1412,\n",
      "          0.9725, 0.9961, 0.3765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5451, 0.9961, 0.7686, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.6275, 0.9961, 0.6118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.3804, 0.9961, 0.9373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3647, 0.9961, 0.9569, 0.0941, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.6510, 0.9961, 0.8275, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.2000, 0.9490, 0.9961, 0.4549, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.6667, 0.9961, 0.6471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.5098, 0.9961, 0.9843, 0.2235, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.7647, 0.9961, 0.2824, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1725, 0.9020, 0.9961, 0.9216, 0.2431, 0.0000, 0.0000,\n",
      "          0.4157, 0.9843, 0.9529, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.1725, 0.9176, 0.9961, 0.9373, 0.6078, 0.5569,\n",
      "          0.9490, 0.9961, 0.5098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.1961, 0.6039, 0.9961, 0.9961, 0.9961,\n",
      "          0.9961, 0.7529, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.5412, 0.7882, 0.7059,\n",
      "          0.6353, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "\n",
    "print(y, x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying first feature (digit) using matplotlib imshow()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAO+0lEQVR4nO3df6zddX3H8der9dK6FpDyKx2UH0IxVAml3hW1G1ZxDlAsLnGDkKaYbmUGJjgyRJYFEompihCNjOQi1c4gBKdIY9gEO02tSu0FC7RWV34UaXtHhRpah7399d4f99Rcyz2fc3p+0/fzkdycc7/v8znfN4f76vec8/3xcUQIwKFvXLcbANAZhB1IgrADSRB2IAnCDiTxhk6u7DBPiIma1MlVAqns1P9pVwx7rFpTYbd9gaQvShov6SsRsbj0+ImapHN9fjOrBFCwKpZXrTX8Nt72eEl3SLpQ0gxJl9me0ejzAWivZj6zz5b0dEQ8GxG7JN0naV5r2gLQas2E/QRJL4z6fVNl2R+xvcj2oO3B3RpuYnUAmtFM2Mf6EuA1x95GxEBE9EdEf58mNLE6AM1oJuybJE0b9fuJkrY01w6Admkm7KslTbd9qu3DJF0qaVlr2gLQag3veouIPbavlvQ9jex6WxIR61rWGYCWamo/e0Q8JOmhFvUCoI04XBZIgrADSRB2IAnCDiRB2IEkCDuQREfPZ0fnbXmgfCLilLsnF+sTv/uzVraDLmLLDiRB2IEkCDuQBGEHkiDsQBKEHUiCXW+HgtlnVS09/PY7i0P/6kfXF+tTG2oIvYgtO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k4YjXTOLSNkd4SjCL68EbN6k8zfU5K3dUrW189eji2Jfn/LahntCbVsVybY9tY07ZzJYdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5LgfPYeMG5m+XLPOxbvLNY/eez3q9Yu+sS1xbGTtapYx6GjqbDb3ihph6S9kvZERH8rmgLQeq3Ysr8nIl5qwfMAaCM+swNJNBv2kPSw7cdsLxrrAbYX2R60Pbhbw02uDkCjmn0bPycittg+TtIjtn8ZEStGPyAiBiQNSCMnwjS5PgANamrLHhFbKrdbJT0gaXYrmgLQeg2H3fYk24fvvy/p/ZLWtqoxAK3VzNv44yU9YHv/83wjIv6rJV0ls+2sI4v178wYKNYvXje/au3wZWuKY/lclUfDYY+IZyWd3cJeALQRu96AJAg7kARhB5Ig7EAShB1IglNcO8BvKL/Mb5w/VKxv2DO5WD/8Y9V3oO0Z5hBljGDLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJsJ+9A4auKl/T4/G3frlYXz1c40TU4V0H2xISYssOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0mwn70DXp1a3k++ee+rxfpHl15frJ+0+ScH3dOhYPwxRxfr7/vhc1VrMyZuLo697u6FxfqJn60x1fW+veV6F7BlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkHNG5SXuP8JQ41+d3bH29YvrqCcX6hu3Hlp/g/E0t7KZ37H3PrGL9tM+uL9ZXL5lZrv/rHQfdU70uPnNusb53+/a2rbtkVSzX9tjmsWo1t+y2l9jeanvtqGVTbD9ie0Pl9qhWNgyg9ep5G/81SRccsOwGScsjYrqk5ZXfAfSwmmGPiBWSth2weJ6kpZX7SyVd0uK+ALRYo1/QHR8RQ5JUuT2u2gNtL7I9aHtwt5h3DOiWtn8bHxEDEdEfEf19Kn9RBaB9Gg37i7anSlLldmvrWgLQDo2GfZmkBZX7CyQ92Jp2ALRLzfPZbd8raa6kY2xvknSTpMWS7re9UNKvJX2knU32uqHvnFmsf2jSymK95n7217FxM2dUrX3+q/9WHDvJe4r1j3+v6ldFkqQPfPWdVWuLf7miOPasw/qK9V2zTi/Wx//w8WK9G2qGPSIuq1LKd3QM8DrG4bJAEoQdSIKwA0kQdiAJwg4kwaWk6+QJ1Y/+u/Dk8qmY/3Dk88X6sqGzG+qpF8S7yr3HLS9VrU0bv684ds5A+RLa054rX0LbfYdVrQ289O7i2LdP3lis9z36i2K9/F/WHWzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJ9rPXadwbJ1atfea4nxbH/j52FetDD51UrE9V9y4lPf6o8oWD9xX2o0vSl067v2pt1sPXFMee8enyfvRxE6v/P5Gk6SurT5s8YVz5Emm3rLi4WD9j5+pivRexZQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJNjPXq/C+ey1PL17zBl0/+BPv/xYsd7OSbWfXVz9csuStPiv7ynWPzjp5WL9vdf+U9XaGd9cVRxbyyuXlKdsvn1q+VLVJQ/+9h0Nj+1VbNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAn2s9dp68WnNTy21vS/z948q1g/9VPl8+WbMfEtrxTru2N8sT7npo8X60d/s329/+ZDOxse++Ph8nZu+p3lawiUJ5PuTTW37LaX2N5qe+2oZTfb3mx7TeXnova2CaBZ9byN/5qkC8ZYfntEzKz8PNTatgC0Ws2wR8QKSds60AuANmrmC7qrbT9ZeZtf9UJlthfZHrQ9uFvl634BaJ9Gw36npNMkzZQ0JOkL1R4YEQMR0R8R/X1q/GQSAM1pKOwR8WJE7I2IfZLukjS7tW0BaLWGwm576qhfPyxpbbXHAugNNfez275X0lxJx9jeJOkmSXNtz9TIqdYbJV3Zxh57wvCbyuekN2PvxPadsf7MreXzslf331asz/r+PxbrZ3ylif3o48r78J/7TPkN4xPnfbHGCqr/eX/s55cXR574/Loaz/36UzPsEXHZGIvvbkMvANqIw2WBJAg7kARhB5Ig7EAShB1IglNc67RnUvue+555dxTrn/7cB4r1PUP/W7V2/Nu2Fsde+XyNqYkXrinWm/HcLeVda+vnl1+XWn++nxg6t2rtpMufKY7dV2PNr0ds2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCfaz12lC4Sp8i144rzj27pNWFut/NqG8V3fTpW8u1idvPqVq7btvLZ/COmfVomJ92r7ylMzjjz22WN/wz6dXra29/EvFsVv3li9j9tGn/7ZYf37FyVVrJ+38SXHsoYgtO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k4Yj2Xcb4QEd4Spzr8zu2vk6Jd55drL984++L9Z/Nuq+V7RyUH+0sH2rxd48uKNY/Nes/i/Urjthy0D3td8Z/LyzWT5//84af+1C1KpZre2wb87rnbNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnOZ28B//SJYn34x+8qP8GsFjZzkP5i4p5i/Vdzm5uw99Ztb6la+4/b3lccO/3rq4v1zh0hcmiouWW3Pc32D2yvt73O9jWV5VNsP2J7Q+X2qPa3C6BR9byN3yPpuog4U9I7JF1le4akGyQtj4jpkpZXfgfQo2qGPSKGIuLxyv0dktZLOkHSPElLKw9bKumSdjUJoHkH9QWd7VMknSNplaTjI2JIGvkHQdJxVcYssj1oe3C3ytcUA9A+dYfd9mRJ35J0bURsr3dcRAxERH9E9PdpQiM9AmiBusJuu08jQb8nIr5dWfyi7amV+lRJ5elCAXRVzVNcbVsjn8m3RcS1o5Z/XtLLEbHY9g2SpkTE9aXnOlRPca3FE8rvaIbnnlWsb353X7G+fkH1qY3vemVacezfH/lCsT5j5RXF+pQH/6RYP+IbjxbraK3SKa717GefI2m+pKds75+s+0ZJiyXdb3uhpF9L+kgrmgXQHjXDHhErJY35L4WkfJtp4HWKw2WBJAg7kARhB5Ig7EAShB1IgktJA4cQLiUNgLADWRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5KoGXbb02z/wPZ62+tsX1NZfrPtzbbXVH4uan+7ABpVz/zseyRdFxGP2z5c0mO2H6nUbo+IW9vXHoBWqWd+9iFJQ5X7O2yvl3RCuxsD0FoH9Znd9imSzpG0qrLoattP2l5i+6gqYxbZHrQ9uFvDTTULoHF1h932ZEnfknRtRGyXdKek0yTN1MiW/wtjjYuIgYjoj4j+Pk1oQcsAGlFX2G33aSTo90TEtyUpIl6MiL0RsU/SXZJmt69NAM2q59t4S7pb0vqIuG3U8qmjHvZhSWtb3x6AVqnn2/g5kuZLesr2msqyGyVdZnumpJC0UdKVbekQQEvU8238Skljzff8UOvbAdAuHEEHJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IwhHRuZXZv5H0/KhFx0h6qWMNHJxe7a1X+5LorVGt7O3kiDh2rEJHw/6alduDEdHftQYKerW3Xu1LordGdao33sYDSRB2IIluh32gy+sv6dXeerUvid4a1ZHeuvqZHUDndHvLDqBDCDuQRFfCbvsC27+y/bTtG7rRQzW2N9p+qjIN9WCXe1lie6vttaOWTbH9iO0Nldsx59jrUm89MY13YZrxrr523Z7+vOOf2W2Pl/Q/kv5S0iZJqyVdFhG/6GgjVdjeKKk/Irp+AIbt8yT9TtK/R8TbKss+J2lbRCyu/EN5VER8skd6u1nS77o9jXdltqKpo6cZl3SJpCvUxdeu0NffqAOvWze27LMlPR0Rz0bELkn3SZrXhT56XkSskLTtgMXzJC2t3F+qkT+WjqvSW0+IiKGIeLxyf4ek/dOMd/W1K/TVEd0I+wmSXhj1+yb11nzvIelh24/ZXtTtZsZwfEQMSSN/PJKO63I/B6o5jXcnHTDNeM+8do1Mf96sboR9rKmkemn/35yImCXpQklXVd6uoj51TePdKWNMM94TGp3+vFndCPsmSdNG/X6ipC1d6GNMEbGlcrtV0gPqvamoX9w/g27ldmuX+/mDXprGe6xpxtUDr103pz/vRthXS5pu+1Tbh0m6VNKyLvTxGrYnVb44ke1Jkt6v3puKepmkBZX7CyQ92MVe/kivTONdbZpxdfm16/r05xHR8R9JF2nkG/lnJP1LN3qo0tebJT1R+VnX7d4k3auRt3W7NfKOaKGkoyUtl7Shcjulh3r7uqSnJD2pkWBN7VJvf66Rj4ZPSlpT+bmo269doa+OvG4cLgskwRF0QBKEHUiCsANJEHYgCcIOJEHYgSQIO5DE/wNhb3LvmwyDaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0][0].view(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting shape of first feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting labels in trainset to check for data imbalance. Labels are counted using a dictionary with keys representing possible label values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "\n",
    "counter_dict = {0 :0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] +=1\n",
    "        total +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying label count. Data does not seem to be imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5923,\n",
       " 1: 6742,\n",
       " 2: 5958,\n",
       " 3: 6131,\n",
       " 4: 5842,\n",
       " 5: 5421,\n",
       " 6: 5918,\n",
       " 7: 6265,\n",
       " 8: 5851,\n",
       " 9: 5949}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming image label counts in ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dependencies for building Feedforward neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net (nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1, 28*28) #array of any size  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3815, -2.1249, -2.4187, -2.3690, -2.2442, -2.2488, -2.2980, -2.3912,\n",
       "         -2.2502, -2.3367]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0583, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1984, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0097, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 1e-3) \n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # data is a batch of features and labels\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y) #used because label is a scaller, use mean-squared for one-hot\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct +=1\n",
    "            total +=1\n",
    "\n",
    "print(f\"Accuracy: {round(correct/total, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[1].view(28, 28))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5, grad_fn=<NotImplemented>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[1].view(-1, 784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct +=1\n",
    "            total +=1\n",
    "\n",
    "print(f\"Accuracy: {round(correct/total, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
